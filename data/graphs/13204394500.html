<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 900px;
                 background-color: #f8fafc;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             

             
             /* position absolute is important and the container has to be relative or absolute as well. */
          div.popup {
                 position:absolute;
                 top:0px;
                 left:0px;
                 display:none;
                 background-color:#f5f4ed;
                 -moz-border-radius: 3px;
                 -webkit-border-radius: 3px;
                 border-radius: 3px;
                 border: 1px solid #808074;
                 box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2);
          }

          /* hide the original tooltip */
          .vis-tooltip {
            display:none;
          }
             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"borderWidth": 4, "borderWidthSelected": 6, "color": {"background": "#f59e0b", "border": "#d97706", "highlight": {"background": "#fbbf24", "border": "#f59e0b"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "13204394500", "image": "https://www.it.kmitl.ac.th/_next/image?url=https%3A%2F%2Fs3.www.it.kmitl.co%2Fwwwitkmitl%2F%25E0%25B8%2581%25E0%25B8%25B4%25E0%25B8%2595%25E0%25B8%25B4%25E0%25B9%258C%25E0%25B8%25AA%25E0%25B8%25B8%25E0%25B8%258A%25E0%25B8%25B2%25E0%25B8%2595-%25E0%25B8%259E%25E0%25B8%25AA%25E0%25B8%25B8%25E0%25B8%25A0%25E0%25B8%25B2-500x500.jpg\u0026w=640\u0026q=75", "label": "Kitsuchart Pasupa", "margin": 12, "node_type": "professor", "physics": false, "shape": "circularImage", "size": 60, "title": "\u003cb\u003eKitsuchart Pasupa\u003c/b\u003e\u003cbr\u003e\u003cspan style=\u0027color:#666\u0027\u003eClick to view profile\u003c/span\u003e"}, {"borderWidth": 3, "borderWidthSelected": 5, "color": {"background": "#06b6d4", "border": "#0891b2", "highlight": {"background": "#22d3ee", "border": "#06b6d4"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "topic_13204394500_Network", "label": "Network", "margin": 10, "node_type": "topic", "physics": false, "shape": "dot", "size": 45, "title": "\u003cb\u003eNetwork\u003c/b\u003e\u003cbr\u003e\u003cspan style=\u0027color:#666\u0027\u003eResearch Area\u003c/span\u003e"}, {"borderWidth": 3, "borderWidthSelected": 5, "color": {"background": "#06b6d4", "border": "#0891b2", "highlight": {"background": "#22d3ee", "border": "#06b6d4"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "topic_13204394500_Deep_Learning", "label": "Deep Learning", "margin": 10, "node_type": "topic", "physics": false, "shape": "dot", "size": 45, "title": "\u003cb\u003eDeep Learning\u003c/b\u003e\u003cbr\u003e\u003cspan style=\u0027color:#666\u0027\u003eResearch Area\u003c/span\u003e"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_0", "label": "Self-attention hierarchical ke...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eSelf-attention hierarchical kernel reservoir state network for inland water level prediction\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2026\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1016/j.engappai.2025.113273\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1016/j.engappai.2025.113273"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_1", "label": "Towards Sentic-Aware Multimoda...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eTowards Sentic-Aware Multimodal Models for\u00a0Cyberbullying Detection in\u00a0Thai Memes\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2026\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/978-981-95-4367-0_16\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/978-981-95-4367-0_16"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_2", "label": "Fin-Ally: Pioneering the Devel...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eFin-Ally: Pioneering the Development of an Advanced, Commonsense-Embedded Conversational AI for Money Matters\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.3233/FAIA251334\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.3233/FAIA251334"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_3", "label": "Optimizing colorectal polyp de...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eOptimizing colorectal polyp detection and localization: Impact of RGB color adjustment on CNN performance\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 1\u003cbr\u003e\u003ca href=\"https://doi.org/10.1016/j.mex.2025.103187\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1016/j.mex.2025.103187"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_4", "label": "Correlated Online k-Nearest Ne...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 36, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eCorrelated Online k-Nearest Neighbors Regressor Chain for\u00a0Online Multi-output Regression\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 3\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/978-981-99-8067-3_3\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/978-981-99-8067-3_3"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_5", "label": "Preface", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003ePreface\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/WI-IAT62293.2024.00005\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/WI-IAT62293.2024.00005"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_6", "label": "ToxVI: a Multimodal LLM-based ...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eToxVI: a Multimodal LLM-based Framework for Generating Intervention in Toxic Code-Mixed Videos\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 2\u003cbr\u003e\u003ca href=\"https://doi.org/10.1145/3627673.3680004\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1145/3627673.3680004"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_7", "label": "HateThaiSent: Sentiment-Aided ...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 39, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eHateThaiSent: Sentiment-Aided Hate Speech Detection in Thai Language\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 13\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/TCSS.2024.3376958\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/TCSS.2024.3376958"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_8", "label": "Weighted error-output recurren...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 37, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eWeighted error-output recurrent Xavier echo state network for concept drift handling in water level prediction\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 6\u003cbr\u003e\u003ca href=\"https://doi.org/10.1016/j.asoc.2024.112055\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1016/j.asoc.2024.112055"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_9", "label": "Optimizing echo state networks...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 36, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eOptimizing echo state networks for continuous gesture recognition in mobile devices: A comparative study\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 5\u003cbr\u003e\u003ca href=\"https://doi.org/10.1016/j.heliyon.2024.e27108\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1016/j.heliyon.2024.e27108"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_10", "label": "Breast cancer prognosis throug...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 37, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eBreast cancer prognosis through the use of multi-modal classifiers: current state of the art and the way forward\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 6\u003cbr\u003e\u003ca href=\"https://doi.org/10.1093/bfgp/elae015\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1093/bfgp/elae015"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_11", "label": "Enhancing Thai Food Recognitio...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eEnhancing Thai Food Recognition Through Multimodal Fusion of Image and Fourier Spectrum\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/978-981-97-5934-7_7\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/978-981-97-5934-7_7"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_12", "label": "Preface", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003ePreface\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 0\u003c/div\u003e"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_13", "label": "FastThaiCaps: A Transformer Ba...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eFastThaiCaps: A Transformer Based Capsule Network for\u00a0Hate Speech Detection in\u00a0Thai Language\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 2\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/978-3-031-30108-7_36\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/978-3-031-30108-7_36"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_14", "label": "Error-output recurrent multi-l...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 38, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eError-output recurrent multi-layer Kernel Reservoir Network for electricity load time series forecasting\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 11\u003cbr\u003e\u003ca href=\"https://doi.org/10.1016/j.engappai.2022.105611\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1016/j.engappai.2022.105611"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_15", "label": "Convolutional neural networks ...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 47, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eConvolutional neural networks based focal loss for class imbalance problem: a case study of canine red blood cells morphology classification\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 36\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/s12652-020-01773-x\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/s12652-020-01773-x"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_16", "label": "Ex-ThaiHate: A Generative Mult...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eEx-ThaiHate: A Generative Multi-task Framework for\u00a0Sentiment and\u00a0Emotion Aware Hate Speech Detection with\u00a0Explanation in\u00a0Thai\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 2\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/978-3-031-43427-3_9\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/978-3-031-43427-3_9"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_17", "label": "Welcome Message from Technical...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eWelcome Message from Technical Program Co-Chairs\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICITEE59582.2023.10317790\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICITEE59582.2023.10317790"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_18", "label": "CowXNet: An automated cow estr...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 50, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eCowXNet: An automated cow estrus detection system\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 50\u003cbr\u003e\u003ca href=\"https://doi.org/10.1016/j.eswa.2022.118550\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1016/j.eswa.2022.118550"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Network_19", "label": "Preface", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003ePreface\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 0\u003c/div\u003e"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Deep_Learning_0", "label": "Detecting Cyberbullying in Tha...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eDetecting Cyberbullying in Thai Memes: A Multimodal Approach Using Deep Learning\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 1\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/CI-NLPSoMe64976.2025.10970667\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/CI-NLPSoMe64976.2025.10970667"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Deep_Learning_1", "label": "Highlight Detection in\u00a0Podcast...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eHighlight Detection in\u00a0Podcasts: A Multimodal Deep Learning Approach\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/978-981-96-6599-0_15\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/978-981-96-6599-0_15"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Deep_Learning_2", "label": "Generating Pseudo-labels for\u00a0C...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eGenerating Pseudo-labels for\u00a0Car Damage Segmentation Using Deep Spectral Method\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 1\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/978-981-99-8184-7_36\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/978-981-99-8184-7_36"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Deep_Learning_3", "label": "HANCaps: A Two-Channel Deep Le...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eHANCaps: A Two-Channel Deep Learning Framework for\u00a0Fake News Detection in\u00a0Thai\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 2\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/978-981-99-8184-7_16\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/978-981-99-8184-7_16"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_13204394500_topic_13204394500_Deep_Learning_4", "label": "Comparative Analysis of Online...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eComparative Analysis of Online and Offline Learning Algorithms with Data Drift Detectors in Multi-Target Time Series\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICITEE62483.2024.10808868\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICITEE62483.2024.10808868"}]);
                  edges = new vis.DataSet([{"color": {"color": "#94a3b8", "opacity": 0.5}, "from": "13204394500", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "expertise", "to": "topic_13204394500_Network", "width": 1}, {"color": {"color": "#94a3b8", "opacity": 0.5}, "from": "13204394500", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "expertise", "to": "topic_13204394500_Deep_Learning", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_0", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_1", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_2", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_3", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_4", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_5", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_6", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_7", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_8", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_9", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_10", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_11", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_12", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_13", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_14", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_15", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_16", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_17", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_18", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Network_19", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Deep_Learning_0", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Deep_Learning_1", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Deep_Learning_2", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Deep_Learning_3", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_13204394500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_13204394500_topic_13204394500_Deep_Learning_4", "width": 1}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"nodes": {"shadow": {"enabled": true, "color": "rgba(0,0,0,0.15)", "size": 12, "x": 3, "y": 3}, "font": {"size": 16, "face": "Arial,sans-serif", "strokeWidth": 0, "align": "center"}}, "edges": {"smooth": {"enabled": true, "type": "curvedCW", "roundness": 0.2}, "color": {"inherit": false}, "width": 2}, "physics": {"enabled": false}, "interaction": {"hover": true, "tooltipDelay": 100, "navigationButtons": true, "keyboard": {"enabled": true}, "zoomView": true, "dragView": true, "dragNodes": true}, "layout": {"randomSeed": 42, "improvedLayout": true, "hierarchical": {"enabled": true, "direction": "LR", "sortMethod": "directed", "nodeSpacing": 200, "levelSeparation": 250, "treeSpacing": 200, "blockShifting": true, "edgeMinimization": true, "parentCentralization": true}}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  
                  // make a custom popup
                      var popup = document.createElement("div");
                      popup.className = 'popup';
                      popupTimeout = null;
                      popup.addEventListener('mouseover', function () {
                          console.log(popup)
                          if (popupTimeout !== null) {
                              clearTimeout(popupTimeout);
                              popupTimeout = null;
                          }
                      });
                      popup.addEventListener('mouseout', function () {
                          if (popupTimeout === null) {
                              hidePopup();
                          }
                      });
                      container.appendChild(popup);


                      // use the popup event to show
                      network.on("showPopup", function (params) {
                          showPopup(params);
                      });

                      // use the hide event to hide it
                      network.on("hidePopup", function (params) {
                          hidePopup();
                      });

                      // hiding the popup through css
                      function hidePopup() {
                          popupTimeout = setTimeout(function () { popup.style.display = 'none'; }, 500);
                      }

                      // showing the popup
                      function showPopup(nodeId) {
                          // get the data from the vis.DataSet
                          var nodeData = nodes.get([nodeId]);
                          popup.innerHTML = nodeData[0].title;

                          // get the position of the node
                          var posCanvas = network.getPositions([nodeId])[nodeId];

                          // get the bounding box of the node
                          var boundingBox = network.getBoundingBox(nodeId);

                          //position tooltip:
                          posCanvas.x = posCanvas.x + 0.5 * (boundingBox.right - boundingBox.left);

                          // convert coordinates to the DOM space
                          var posDOM = network.canvasToDOM(posCanvas);

                          // Give it an offset
                          posDOM.x += 10;
                          posDOM.y -= 20;

                          // show and place the tooltip.
                          popup.style.display = 'block';
                          popup.style.top = posDOM.y + 'px';
                          popup.style.left = posDOM.x + 'px';
                      }
                  


                  

                  return network;

              }
              drawGraph();
        </script>
    
        <script type="text/javascript">
        network.on("click", function (params) {
            if (params.nodes.length > 0) {
                var nodeId = params.nodes[0];
                var node = nodes.get(nodeId);
                if (node && node.url) {
                    window.open(node.url, '_blank');
                }
            }
        });
        </script>
        </body>
</html>