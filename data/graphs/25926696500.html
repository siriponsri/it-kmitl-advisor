<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 900px;
                 background-color: #f8fafc;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             

             
             /* position absolute is important and the container has to be relative or absolute as well. */
          div.popup {
                 position:absolute;
                 top:0px;
                 left:0px;
                 display:none;
                 background-color:#f5f4ed;
                 -moz-border-radius: 3px;
                 -webkit-border-radius: 3px;
                 border-radius: 3px;
                 border: 1px solid #808074;
                 box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2);
          }

          /* hide the original tooltip */
          .vis-tooltip {
            display:none;
          }
             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"borderWidth": 4, "borderWidthSelected": 6, "color": {"background": "#f59e0b", "border": "#d97706", "highlight": {"background": "#fbbf24", "border": "#f59e0b"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "25926696500", "image": "https://www.it.kmitl.ac.th/_next/image?url=https%3A%2F%2Fs3.www.it.kmitl.co%2Fwwwitkmitl%2F%25E0%25B8%2581%25E0%25B8%25B1%25E0%25B8%2599%25E0%25B8%2595%25E0%25B9%258C%25E0%25B8%259E%25E0%25B8%2587%25E0%25B8%25A9%25E0%25B9%258C-%25E0%25B8%25A7%25E0%25B8%25A3%25E0%25B8%25A3%25E0%25B8%25B1%25E0%25B8%2595%25E0%25B8%2599%25E0%25B9%258C%25E0%25B8%259B%25E0%25B8%25B1%25E0%25B8%258D%25E0%25B8%258D%25E0%25B8%25B2-500x500.jpg\u0026w=640\u0026q=75", "label": "Kuntpong Woraratpanya", "margin": 12, "node_type": "professor", "physics": false, "shape": "circularImage", "size": 60, "title": "\u003cb\u003eKuntpong Woraratpanya\u003c/b\u003e\u003cbr\u003e\u003cspan style=\u0027color:#666\u0027\u003eClick to view profile\u003c/span\u003e"}, {"borderWidth": 3, "borderWidthSelected": 5, "color": {"background": "#06b6d4", "border": "#0891b2", "highlight": {"background": "#22d3ee", "border": "#06b6d4"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "topic_25926696500_Deep_Learning", "label": "Deep Learning", "margin": 10, "node_type": "topic", "physics": false, "shape": "dot", "size": 45, "title": "\u003cb\u003eDeep Learning\u003c/b\u003e\u003cbr\u003e\u003cspan style=\u0027color:#666\u0027\u003eResearch Area\u003c/span\u003e"}, {"borderWidth": 3, "borderWidthSelected": 5, "color": {"background": "#06b6d4", "border": "#0891b2", "highlight": {"background": "#22d3ee", "border": "#06b6d4"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "topic_25926696500_Neural_Network", "label": "Neural Network", "margin": 10, "node_type": "topic", "physics": false, "shape": "dot", "size": 45, "title": "\u003cb\u003eNeural Network\u003c/b\u003e\u003cbr\u003e\u003cspan style=\u0027color:#666\u0027\u003eResearch Area\u003c/span\u003e"}, {"borderWidth": 3, "borderWidthSelected": 5, "color": {"background": "#06b6d4", "border": "#0891b2", "highlight": {"background": "#22d3ee", "border": "#06b6d4"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "topic_25926696500_Prediction", "label": "Prediction", "margin": 10, "node_type": "topic", "physics": false, "shape": "dot", "size": 45, "title": "\u003cb\u003ePrediction\u003c/b\u003e\u003cbr\u003e\u003cspan style=\u0027color:#666\u0027\u003eResearch Area\u003c/span\u003e"}, {"borderWidth": 3, "borderWidthSelected": 5, "color": {"background": "#06b6d4", "border": "#0891b2", "highlight": {"background": "#22d3ee", "border": "#06b6d4"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "topic_25926696500_Classification", "label": "Classification", "margin": 10, "node_type": "topic", "physics": false, "shape": "dot", "size": 45, "title": "\u003cb\u003eClassification\u003c/b\u003e\u003cbr\u003e\u003cspan style=\u0027color:#666\u0027\u003eResearch Area\u003c/span\u003e"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_0", "label": "Advancing GAN Evaluation: The ...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eAdvancing GAN Evaluation: The Advanced Mahalanobis Distance Learning Metric for Realistic Car Damage Image Assessment\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2026\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ACCESS.2026.3657196\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ACCESS.2026.3657196"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_1", "label": "Evaluating the effectiveness o...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eEvaluating the effectiveness of facial actions features for the early detection of driver drowsiness in driving safety monitoring system\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.21924/cst.10.1.2025.1594\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.21924/cst.10.1.2025.1594"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_2", "label": "Anomaly Signal Imputation Usin...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eAnomaly Signal Imputation Using Latent Coordination Relations\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 1\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ACCESS.2024.3448236\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ACCESS.2024.3448236"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_3", "label": "Enhancing Thai Food Recognitio...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eEnhancing Thai Food Recognition Through Multimodal Fusion of Image and Fourier Spectrum\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/978-981-97-5934-7_7\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/978-981-97-5934-7_7"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_4", "label": "Exploring the i3DVAE-LSTM Fram...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eExploring the i3DVAE-LSTM Framework for Generating Exceptionally Rare Anomaly Signals\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICITEE59582.2023.10317760\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICITEE59582.2023.10317760"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_5", "label": "Fractal Dimension in Deep Lear...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eFractal Dimension in Deep Learning\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICITEE59582.2023.10317679\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICITEE59582.2023.10317679"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_6", "label": "AI-enabled Exit Strategy of Em...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eAI-enabled Exit Strategy of Emergency Vehicle Preemption\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 1\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICITEE59582.2023.10317753\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICITEE59582.2023.10317753"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_7", "label": "Exploring LSTM and CNN Archite...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 36, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eExploring LSTM and CNN Architectures for Sign Language Translation\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 5\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICITEE59582.2023.10317660\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICITEE59582.2023.10317660"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_8", "label": "3DVAE-LSTM for Extremely Rare ...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003e3DVAE-LSTM for Extremely Rare Anomaly Signal Generation\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2022\u003cbr\u003eCitations: 2\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICITEE56407.2022.9954112\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICITEE56407.2022.9954112"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_9", "label": "Vector learning representation...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 38, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eVector learning representation for generalized speech emotion recognition\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2022\u003cbr\u003eCitations: 11\u003cbr\u003e\u003ca href=\"https://doi.org/10.1016/j.heliyon.2022.e09196\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1016/j.heliyon.2022.e09196"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_10", "label": "Evaluation of deep learning al...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 48, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eEvaluation of deep learning algorithms for semantic segmentation of car parts\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2022\u003cbr\u003eCitations: 41\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/s40747-021-00397-8\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/s40747-021-00397-8"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_11", "label": "ADGAS: An Advanced Data Genera...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eADGAS: An Advanced Data Generation for Anomalous Signals\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2021\u003cbr\u003eCitations: 2\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/978-3-030-79757-7_14\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/978-3-030-79757-7_14"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_12", "label": "A Unified Framework for Salien...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eA Unified Framework for Saliency Segmentation\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2021\u003cbr\u003eCitations: 1\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/978-3-030-79757-7_19\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/978-3-030-79757-7_19"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_13", "label": "Enhancement of Anime Imaging E...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 36, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eEnhancement of Anime Imaging Enlargement using Modified Super-Resolution CNN\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2021\u003cbr\u003eCitations: 3\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICITEE53064.2021.9611842\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICITEE53064.2021.9611842"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_14", "label": "3DVAE-ERSG: 3D Variational Aut...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 36, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003e3DVAE-ERSG: 3D Variational Autoencoder for Extremely Rare Signal Generation\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2021\u003cbr\u003eCitations: 5\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICITEE53064.2021.9611955\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICITEE53064.2021.9611955"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_15", "label": "A data generation framework fo...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 37, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eA data generation framework for extremely rare case signals\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2021\u003cbr\u003eCitations: 8\u003cbr\u003e\u003ca href=\"https://doi.org/10.1016/j.heliyon.2021.e07687\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1016/j.heliyon.2021.e07687"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_16", "label": "Local Sigmoid Method: Non-Iter...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 37, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eLocal Sigmoid Method: Non-Iterative Deterministic Learning Algorithm for Automatic Model Construction of Neural Network\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2020\u003cbr\u003eCitations: 7\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ACCESS.2020.2968983\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ACCESS.2020.2968983"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_17", "label": "An Efficient Hola Filter for S...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eAn Efficient Hola Filter for Saliency Detection\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2020\u003cbr\u003eCitations: 2\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICITEE49829.2020.9271690\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICITEE49829.2020.9271690"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_18", "label": "Deep Residual Local Feature Le...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 37, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eDeep Residual Local Feature Learning for Speech Emotion Recognition\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2020\u003cbr\u003eCitations: 6\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/978-3-030-63830-6_21\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/978-3-030-63830-6_21"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_19", "label": "Robust and Unified VLC Decodin...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 39, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eRobust and Unified VLC Decoding System for Square Wave Quadrature Amplitude Modulation Using Deep Learning Approach\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2019\u003cbr\u003eCitations: 14\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ACCESS.2019.2952465\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ACCESS.2019.2952465"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_20", "label": "Square Wave Quadrature Amplitu...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 38, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eSquare Wave Quadrature Amplitude Modulation for Visible Light Communication Using Image Sensor\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2019\u003cbr\u003eCitations: 10\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ACCESS.2019.2928417\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ACCESS.2019.2928417"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Deep_Learning_21", "label": "Thai Dependency Parsing with C...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 39, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eThai Dependency Parsing with Character Embedding\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2019\u003cbr\u003eCitations: 13\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICITEED.2019.8930002\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICITEED.2019.8930002"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Neural_Network_0", "label": "A robust-texture convolutional...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eA robust-texture convolutional neural network\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2019\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.22452/mjcs.sp2019no2.9\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.22452/mjcs.sp2019no2.9"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Prediction_0", "label": "LSCR: Latent Space Coordinatio...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eLSCR: Latent Space Coordination Relation for Anomaly Prediction\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICITEE59582.2023.10317782\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICITEE59582.2023.10317782"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_25926696500_topic_25926696500_Classification_0", "label": "Car Damage Detection and Class...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 43, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eCar Damage Detection and Classification\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2020\u003cbr\u003eCitations: 25\u003cbr\u003e\u003ca href=\"https://doi.org/10.1145/3406601.3406651\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1145/3406601.3406651"}]);
                  edges = new vis.DataSet([{"color": {"color": "#94a3b8", "opacity": 0.5}, "from": "25926696500", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "expertise", "to": "topic_25926696500_Deep_Learning", "width": 1}, {"color": {"color": "#94a3b8", "opacity": 0.5}, "from": "25926696500", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "expertise", "to": "topic_25926696500_Neural_Network", "width": 1}, {"color": {"color": "#94a3b8", "opacity": 0.5}, "from": "25926696500", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "expertise", "to": "topic_25926696500_Prediction", "width": 1}, {"color": {"color": "#94a3b8", "opacity": 0.5}, "from": "25926696500", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "expertise", "to": "topic_25926696500_Classification", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_0", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_1", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_2", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_3", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_4", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_5", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_6", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_7", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_8", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_9", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_10", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_11", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_12", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_13", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_14", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_15", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_16", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_17", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_18", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_19", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_20", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Deep_Learning_21", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Neural_Network", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Neural_Network_0", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Prediction", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Prediction_0", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_25926696500_Classification", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_25926696500_topic_25926696500_Classification_0", "width": 1}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"nodes": {"shadow": {"enabled": true, "color": "rgba(0,0,0,0.15)", "size": 12, "x": 3, "y": 3}, "font": {"size": 16, "face": "Arial,sans-serif", "strokeWidth": 0, "align": "center"}}, "edges": {"smooth": {"enabled": true, "type": "curvedCW", "roundness": 0.2}, "color": {"inherit": false}, "width": 2}, "physics": {"enabled": false}, "interaction": {"hover": true, "tooltipDelay": 100, "navigationButtons": true, "keyboard": {"enabled": true}, "zoomView": true, "dragView": true, "dragNodes": true}, "layout": {"randomSeed": 42, "improvedLayout": true, "hierarchical": {"enabled": true, "direction": "LR", "sortMethod": "directed", "nodeSpacing": 200, "levelSeparation": 250, "treeSpacing": 200, "blockShifting": true, "edgeMinimization": true, "parentCentralization": true}}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  
                  // make a custom popup
                      var popup = document.createElement("div");
                      popup.className = 'popup';
                      popupTimeout = null;
                      popup.addEventListener('mouseover', function () {
                          console.log(popup)
                          if (popupTimeout !== null) {
                              clearTimeout(popupTimeout);
                              popupTimeout = null;
                          }
                      });
                      popup.addEventListener('mouseout', function () {
                          if (popupTimeout === null) {
                              hidePopup();
                          }
                      });
                      container.appendChild(popup);


                      // use the popup event to show
                      network.on("showPopup", function (params) {
                          showPopup(params);
                      });

                      // use the hide event to hide it
                      network.on("hidePopup", function (params) {
                          hidePopup();
                      });

                      // hiding the popup through css
                      function hidePopup() {
                          popupTimeout = setTimeout(function () { popup.style.display = 'none'; }, 500);
                      }

                      // showing the popup
                      function showPopup(nodeId) {
                          // get the data from the vis.DataSet
                          var nodeData = nodes.get([nodeId]);
                          popup.innerHTML = nodeData[0].title;

                          // get the position of the node
                          var posCanvas = network.getPositions([nodeId])[nodeId];

                          // get the bounding box of the node
                          var boundingBox = network.getBoundingBox(nodeId);

                          //position tooltip:
                          posCanvas.x = posCanvas.x + 0.5 * (boundingBox.right - boundingBox.left);

                          // convert coordinates to the DOM space
                          var posDOM = network.canvasToDOM(posCanvas);

                          // Give it an offset
                          posDOM.x += 10;
                          posDOM.y -= 20;

                          // show and place the tooltip.
                          popup.style.display = 'block';
                          popup.style.top = posDOM.y + 'px';
                          popup.style.left = posDOM.x + 'px';
                      }
                  


                  

                  return network;

              }
              drawGraph();
        </script>
    
        <script type="text/javascript">
        network.on("click", function (params) {
            if (params.nodes.length > 0) {
                var nodeId = params.nodes[0];
                var node = nodes.get(nodeId);
                if (node && node.url) {
                    window.open(node.url, '_blank');
                }
            }
        });
        </script>
        </body>
</html>