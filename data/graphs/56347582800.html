<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 900px;
                 background-color: #f8fafc;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             

             
             /* position absolute is important and the container has to be relative or absolute as well. */
          div.popup {
                 position:absolute;
                 top:0px;
                 left:0px;
                 display:none;
                 background-color:#f5f4ed;
                 -moz-border-radius: 3px;
                 -webkit-border-radius: 3px;
                 border-radius: 3px;
                 border: 1px solid #808074;
                 box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2);
          }

          /* hide the original tooltip */
          .vis-tooltip {
            display:none;
          }
             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"borderWidth": 4, "borderWidthSelected": 6, "color": {"background": "#f59e0b", "border": "#d97706", "highlight": {"background": "#fbbf24", "border": "#f59e0b"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "56347582800", "image": "https://www.it.kmitl.ac.th/_next/image?url=https%3A%2F%2Fs3.www.it.kmitl.co%2Fwwwitkmitl%2F%25E0%25B8%2598%25E0%25B8%25A3%25E0%25B8%25B2%25E0%25B8%25A7%25E0%25B8%25B4%25E0%25B9%2580%25E0%25B8%258A%25E0%25B8%25A9%25E0%25B8%2590%25E0%25B9%258C-%25E0%25B8%2598%25E0%25B8%25B4%25E0%25B8%2595%25E0%25B8%25B4%25E0%25B8%2588%25E0%25B8%25A3%25E0%25B8%25B9%25E0%25B8%258D%25E0%25B9%2582%25E0%25B8%25A3%25E0%25B8%2588%25E0%25B8%2599%25E0%25B9%258C-500x500.jpg\u0026w=640\u0026q=75", "label": "Taravichet Titijaroonroj", "margin": 12, "node_type": "professor", "physics": false, "shape": "circularImage", "size": 60, "title": "\u003cb\u003eTaravichet Titijaroonroj\u003c/b\u003e\u003cbr\u003e\u003cspan style=\u0027color:#666\u0027\u003eClick to view profile\u003c/span\u003e"}, {"borderWidth": 3, "borderWidthSelected": 5, "color": {"background": "#06b6d4", "border": "#0891b2", "highlight": {"background": "#22d3ee", "border": "#06b6d4"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "topic_56347582800_Deep_Learning", "label": "Deep Learning", "margin": 10, "node_type": "topic", "physics": false, "shape": "dot", "size": 45, "title": "\u003cb\u003eDeep Learning\u003c/b\u003e\u003cbr\u003e\u003cspan style=\u0027color:#666\u0027\u003eResearch Area\u003c/span\u003e"}, {"borderWidth": 3, "borderWidthSelected": 5, "color": {"background": "#06b6d4", "border": "#0891b2", "highlight": {"background": "#22d3ee", "border": "#06b6d4"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "topic_56347582800_Classification", "label": "Classification", "margin": 10, "node_type": "topic", "physics": false, "shape": "dot", "size": 45, "title": "\u003cb\u003eClassification\u003c/b\u003e\u003cbr\u003e\u003cspan style=\u0027color:#666\u0027\u003eResearch Area\u003c/span\u003e"}, {"borderWidth": 3, "borderWidthSelected": 5, "color": {"background": "#06b6d4", "border": "#0891b2", "highlight": {"background": "#22d3ee", "border": "#06b6d4"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "topic_56347582800_Semantic", "label": "Semantic", "margin": 10, "node_type": "topic", "physics": false, "shape": "dot", "size": 45, "title": "\u003cb\u003eSemantic\u003c/b\u003e\u003cbr\u003e\u003cspan style=\u0027color:#666\u0027\u003eResearch Area\u003c/span\u003e"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_0", "label": "Comparative performance of dee...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eComparative performance of deep learning models and non-dermatologists in diagnosing psoriasis, dermatophytosis, and eczema\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2026\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1038/s41598-025-29562-6\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1038/s41598-025-29562-6"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_1", "label": "Deep learning-based classifica...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eDeep learning-based classification of lymphedema and other lower limb edema diseases using clinical images\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2025\u003cbr\u003eCitations: 1\u003cbr\u003e\u003ca href=\"https://doi.org/10.1038/s41598-025-97564-5\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1038/s41598-025-97564-5"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_2", "label": "LymphoNet: A Deep Learning for...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eLymphoNet: A Deep Learning for Lymph Node Detection from Histological Image\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2024\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ACCESS.2024.3487260\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ACCESS.2024.3487260"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_3", "label": "Skin Video-based Blood Pressur...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 36, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eSkin Video-based Blood Pressure Approximation Using CHROM with LSTM-NN\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 4\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/KST57286.2023.10086816\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/KST57286.2023.10086816"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_4", "label": "Spatial-Frequency Redistributi...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eSpatial-Frequency Redistribution-based Saliency Region Detection for Thai Text Localisation\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2022\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.37936/ecti-cit.2022161.245320\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.37936/ecti-cit.2022161.245320"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_5", "label": "Automatic Thai Ticket Classifi...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 36, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eAutomatic Thai Ticket Classification By Using Machine Learning For IT Infrastructure Company\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2022\u003cbr\u003eCitations: 3\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/JCSSE54890.2022.9836250\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/JCSSE54890.2022.9836250"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_6", "label": "Chertify: Wood Identification-...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eChertify: Wood Identification-Based Mobile Cross-platform by\u00a0Deep Learning Technique\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2022\u003cbr\u003eCitations: 1\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/978-3-030-99948-3_8\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/978-3-030-99948-3_8"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_7", "label": "Heart Rate Estimation by PCA w...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 36, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eHeart Rate Estimation by PCA with LSTM from Video-based Plethysmography Under Periodic Noise\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2022\u003cbr\u003eCitations: 3\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICSEC56337.2022.10049315\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICSEC56337.2022.10049315"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_8", "label": "Seven Segment Display Detectio...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eSeven Segment Display Detection and Recognition via Deep Learning Technique\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2022\u003cbr\u003eCitations: 2\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ECTI-CON54298.2022.9795620\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ECTI-CON54298.2022.9795620"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_9", "label": "Drugtionary: Drug Pill Image D...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 36, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eDrugtionary: Drug Pill Image Detection and\u00a0Recognition Based on\u00a0Deep Learning\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2022\u003cbr\u003eCitations: 4\u003cbr\u003e\u003ca href=\"https://doi.org/10.1007/978-3-030-99948-3_5\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1007/978-3-030-99948-3_5"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_10", "label": "Blood Vessels Detection by Reg...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eBlood Vessels Detection by Regional-based CNN for CT Scan of Lower Extremities\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2022\u003cbr\u003eCitations: 1\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICSEC56337.2022.10049364\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICSEC56337.2022.10049364"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_11", "label": "Proposed Structural Validation...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eProposed Structural Validation-based Testing for Object-Oriented Programming\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2021\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/KST51265.2021.9415812\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/KST51265.2021.9415812"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_12", "label": "Intelligent approach to automa...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 37, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eIntelligent approach to automated star-schema construction using a knowledge base\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2021\u003cbr\u003eCitations: 7\u003cbr\u003e\u003ca href=\"https://doi.org/10.1016/j.eswa.2021.115226\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1016/j.eswa.2021.115226"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_13", "label": "Data augmentation based on mul...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eData augmentation based on multiscale radon transform for seven segment display recognition\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2020\u003cbr\u003eCitations: 2\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/KST48564.2020.9059315\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/KST48564.2020.9059315"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_14", "label": "Regional covariance matrix-bas...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 37, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eRegional covariance matrix-based two-dimensional PCA for face recognition\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2020\u003cbr\u003eCitations: 8\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/KST48564.2020.9059421\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/KST48564.2020.9059421"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_15", "label": "Improved adaptive spectrum sca...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eImproved adaptive spectrum scale-space in frequency domain for saliency detection\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2020\u003cbr\u003eCitations: 1\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/KST48564.2020.9059527\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/KST48564.2020.9059527"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_16", "label": "An Individual Local Mean-based...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 37, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eAn Individual Local Mean-based 2DPCA for Face Recognition under Illumination Effects\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2019\u003cbr\u003eCitations: 7\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/JCSSE.2019.8864163\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/JCSSE.2019.8864163"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_17", "label": "Seven Segment Display Detectio...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 38, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eSeven Segment Display Detection and Recognition using Predefined HSV Color Slicing Technique\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2019\u003cbr\u003eCitations: 11\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/JCSSE.2019.8864189\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/JCSSE.2019.8864189"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_18", "label": "Modified Scale-Space Analysis ...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 36, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eModified Scale-Space Analysis in Frequency Domain Based on Adaptive Multiscale Gaussian Filter for Saliency Detection\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2019\u003cbr\u003eCitations: 5\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/JCSSE.2019.8864211\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/JCSSE.2019.8864211"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_19", "label": "Modified Stroke Width Transfor...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 36, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eModified Stroke Width Transform for Thai Text Detection\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2018\u003cbr\u003eCitations: 4\u003cbr\u003e\u003ca href=\"https://doi.org/10.23919/INCIT.2018.8584869\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.23919/INCIT.2018.8584869"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_20", "label": "Image Denoising Based on Struc...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eImage Denoising Based on Structural BIMF\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2018\u003cbr\u003eCitations: 1\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICSEC.2017.8443804\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICSEC.2017.8443804"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Deep_Learning_21", "label": "Texture analysis assessment fo...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eTexture analysis assessment for images\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2017\u003cbr\u003eCitations: 1\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICITEED.2016.7863254\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICITEED.2016.7863254"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Classification_0", "label": "Chatbot-Powered Orchid Leaf Di...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eChatbot-Powered Orchid Leaf Disease Classification and Management for Improved Farming\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2023\u003cbr\u003eCitations: 0\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/InCIT60207.2023.10413171\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/InCIT60207.2023.10413171"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Classification_1", "label": "Automatic Lymph Node Classific...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 35, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eAutomatic Lymph Node Classification with Convolutional Neural Network\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2022\u003cbr\u003eCitations: 2\u003cbr\u003e\u003ca href=\"https://doi.org/10.1109/ICITEE56407.2022.9954045\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.1109/ICITEE56407.2022.9954045"}, {"borderWidth": 2, "borderWidthSelected": 4, "color": {"background": "#1e3a8a", "border": "#1e40af", "highlight": {"background": "#3b82f6", "border": "#2563eb"}}, "fixed": false, "font": {"color": "#1e293b"}, "id": "paper_56347582800_topic_56347582800_Semantic_0", "label": "A semantic approach to automat...", "margin": 8, "node_type": "paper", "physics": false, "shape": "dot", "size": 36, "title": "\u003cdiv style=\u0027max-width:300px\u0027\u003e\u003cb\u003eA semantic approach to automated design and construction of star schemas\u003c/b\u003e\u003cbr\u003e\u003cbr\u003eYear: 2021\u003cbr\u003eCitations: 3\u003cbr\u003e\u003ca href=\"https://doi.org/10.14456/easr.2021.54\" target=\"_blank\" style=\"color:#3b82f6\"\u003eView Paper\u003c/a\u003e\u003c/div\u003e\u003cbr\u003e\u003ci style=\"color:#3b82f6\"\u003eClick to open\u003c/i\u003e", "url": "https://doi.org/10.14456/easr.2021.54"}]);
                  edges = new vis.DataSet([{"color": {"color": "#94a3b8", "opacity": 0.5}, "from": "56347582800", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "expertise", "to": "topic_56347582800_Deep_Learning", "width": 1}, {"color": {"color": "#94a3b8", "opacity": 0.5}, "from": "56347582800", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "expertise", "to": "topic_56347582800_Classification", "width": 1}, {"color": {"color": "#94a3b8", "opacity": 0.5}, "from": "56347582800", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "expertise", "to": "topic_56347582800_Semantic", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_0", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_1", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_2", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_3", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_4", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_5", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_6", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_7", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_8", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_9", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_10", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_11", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_12", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_13", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_14", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_15", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_16", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_17", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_18", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_19", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_20", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Deep_Learning", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Deep_Learning_21", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Classification", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Classification_0", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Classification", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Classification_1", "width": 1}, {"color": {"color": "#cbd5e1", "opacity": 0.5}, "from": "topic_56347582800_Semantic", "smooth": {"enabled": true, "roundness": 0.6, "type": "continuous"}, "title": "contains", "to": "paper_56347582800_topic_56347582800_Semantic_0", "width": 1}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"nodes": {"shadow": {"enabled": true, "color": "rgba(0,0,0,0.15)", "size": 12, "x": 3, "y": 3}, "font": {"size": 16, "face": "Arial,sans-serif", "strokeWidth": 0, "align": "center"}}, "edges": {"smooth": {"enabled": true, "type": "curvedCW", "roundness": 0.2}, "color": {"inherit": false}, "width": 2}, "physics": {"enabled": false}, "interaction": {"hover": true, "tooltipDelay": 100, "navigationButtons": true, "keyboard": {"enabled": true}, "zoomView": true, "dragView": true, "dragNodes": true}, "layout": {"randomSeed": 42, "improvedLayout": true, "hierarchical": {"enabled": true, "direction": "LR", "sortMethod": "directed", "nodeSpacing": 200, "levelSeparation": 250, "treeSpacing": 200, "blockShifting": true, "edgeMinimization": true, "parentCentralization": true}}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  
                  // make a custom popup
                      var popup = document.createElement("div");
                      popup.className = 'popup';
                      popupTimeout = null;
                      popup.addEventListener('mouseover', function () {
                          console.log(popup)
                          if (popupTimeout !== null) {
                              clearTimeout(popupTimeout);
                              popupTimeout = null;
                          }
                      });
                      popup.addEventListener('mouseout', function () {
                          if (popupTimeout === null) {
                              hidePopup();
                          }
                      });
                      container.appendChild(popup);


                      // use the popup event to show
                      network.on("showPopup", function (params) {
                          showPopup(params);
                      });

                      // use the hide event to hide it
                      network.on("hidePopup", function (params) {
                          hidePopup();
                      });

                      // hiding the popup through css
                      function hidePopup() {
                          popupTimeout = setTimeout(function () { popup.style.display = 'none'; }, 500);
                      }

                      // showing the popup
                      function showPopup(nodeId) {
                          // get the data from the vis.DataSet
                          var nodeData = nodes.get([nodeId]);
                          popup.innerHTML = nodeData[0].title;

                          // get the position of the node
                          var posCanvas = network.getPositions([nodeId])[nodeId];

                          // get the bounding box of the node
                          var boundingBox = network.getBoundingBox(nodeId);

                          //position tooltip:
                          posCanvas.x = posCanvas.x + 0.5 * (boundingBox.right - boundingBox.left);

                          // convert coordinates to the DOM space
                          var posDOM = network.canvasToDOM(posCanvas);

                          // Give it an offset
                          posDOM.x += 10;
                          posDOM.y -= 20;

                          // show and place the tooltip.
                          popup.style.display = 'block';
                          popup.style.top = posDOM.y + 'px';
                          popup.style.left = posDOM.x + 'px';
                      }
                  


                  

                  return network;

              }
              drawGraph();
        </script>
    
        <script type="text/javascript">
        network.on("click", function (params) {
            if (params.nodes.length > 0) {
                var nodeId = params.nodes[0];
                var node = nodes.get(nodeId);
                if (node && node.url) {
                    window.open(node.url, '_blank');
                }
            }
        });
        </script>
        </body>
</html>